{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "126db5b6",
   "metadata": {},
   "source": [
    "# Modeling #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316c2a0",
   "metadata": {},
   "source": [
    "## Import APIs ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89b05c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import wfdb\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1acd02",
   "metadata": {},
   "source": [
    "## Load data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd8d169",
   "metadata": {},
   "source": [
    "### Metadata ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ced8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbxl_df = pd.read_csv('./cleaned_data/cleaned_ptbxl_metadata.csv', index_col='ecg_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2248b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>device</th>\n",
       "      <th>validated_by_human</th>\n",
       "      <th>diagnostic_superclass</th>\n",
       "      <th>strat_fold</th>\n",
       "      <th>filename_lr</th>\n",
       "      <th>filename_hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecg_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00001_lr</td>\n",
       "      <td>records500/00000/00001_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>2</td>\n",
       "      <td>records100/00000/00002_lr</td>\n",
       "      <td>records500/00000/00002_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>5</td>\n",
       "      <td>records100/00000/00003_lr</td>\n",
       "      <td>records500/00000/00003_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00004_lr</td>\n",
       "      <td>records500/00000/00004_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>4</td>\n",
       "      <td>records100/00000/00005_lr</td>\n",
       "      <td>records500/00000/00005_hr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  sex     device  validated_by_human diagnostic_superclass  \\\n",
       "ecg_id                                                                   \n",
       "1       56.0    1  CS-12   E                True              ['NORM']   \n",
       "2       19.0    0  CS-12   E                True              ['NORM']   \n",
       "3       37.0    1  CS-12   E                True              ['NORM']   \n",
       "4       24.0    0  CS-12   E                True              ['NORM']   \n",
       "5       19.0    1  CS-12   E                True              ['NORM']   \n",
       "\n",
       "        strat_fold                filename_lr                filename_hr  \n",
       "ecg_id                                                                    \n",
       "1                3  records100/00000/00001_lr  records500/00000/00001_hr  \n",
       "2                2  records100/00000/00002_lr  records500/00000/00002_hr  \n",
       "3                5  records100/00000/00003_lr  records500/00000/00003_hr  \n",
       "4                3  records100/00000/00004_lr  records500/00000/00004_hr  \n",
       "5                4  records100/00000/00005_lr  records500/00000/00005_hr  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptbxl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee970c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>device</th>\n",
       "      <th>validated_by_human</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecg_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  sex     device  validated_by_human\n",
       "ecg_id                                          \n",
       "1       56.0    1  CS-12   E                True\n",
       "2       19.0    0  CS-12   E                True\n",
       "3       37.0    1  CS-12   E                True\n",
       "4       24.0    0  CS-12   E                True\n",
       "5       19.0    1  CS-12   E                True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = ptbxl_df.loc[:, ['age', 'sex', 'device', 'validated_by_human']].copy()\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4c27e",
   "metadata": {},
   "source": [
    "### Waveform data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b23d07cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21799, 1000, 12)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_data = []\n",
    "for idx in ptbxl_df.index:\n",
    "    record_path = ptbxl_df.loc[idx]['filename_hr']\n",
    "    waveform_df = pd.read_csv('./cleaned_data/waveform_data/' + record_path + '.csv', index_col='Time (s)')\n",
    "    waveform_data.append(waveform_df)\n",
    "waveform_data = np.array(waveform_data)\n",
    "waveform_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dab560a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"./cleaned_data/waveform_np.npy\", waveform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a322ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_data = np.load(\"./cleaned_data/waveform_np.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c09649",
   "metadata": {},
   "source": [
    "## Create recommended train-test split ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ca5dc",
   "metadata": {},
   "source": [
    "This recommended train-test split code was obtained from the downloaded folder with the dataset: https://physionet.org/content/ptb-xl/1.0.3/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd3e8ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make tensors\n",
    "transformers = [\n",
    "    ('num', StandardScaler(), ['age']),\n",
    "    ('cat', OneHotEncoder(), ['sex', 'device', 'validated_by_human'])\n",
    "]\n",
    "\n",
    "ct = ColumnTransformer(transformers, remainder='passthrough')\n",
    "metadata = ct.fit_transform(metadata)\n",
    "\n",
    "#make dense array\n",
    "metadata  = metadata.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11c74a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19601, 1000, 12)\n",
      "(19601, 16)\n",
      "(19601,)\n",
      "\n",
      "(2198, 1000, 12)\n",
      "(2198, 16)\n",
      "(2198,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "test_fold = 10\n",
    "\n",
    "# Train\n",
    "waveform_train = waveform_data[np.where(ptbxl_df.strat_fold != test_fold)]\n",
    "metadata_train = metadata[ptbxl_df.strat_fold != test_fold]\n",
    "y_train = ptbxl_df[ptbxl_df.strat_fold != test_fold].diagnostic_superclass\n",
    "\n",
    "# Test\n",
    "waveform_test = waveform_data[np.where(ptbxl_df.strat_fold == test_fold)]\n",
    "metadata_test = metadata[ptbxl_df.strat_fold == test_fold]\n",
    "y_test = ptbxl_df[ptbxl_df.strat_fold == test_fold].diagnostic_superclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af1973",
   "metadata": {},
   "source": [
    "## Normalize data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687633e9",
   "metadata": {},
   "source": [
    "Only waveform train data is normalized here; may need to normalize other data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6065566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code generated from Bing Copilot\n",
    "\n",
    "# Initialize a new array for the normalized data\n",
    "normalized_waveform_train = np.empty_like(waveform_train)\n",
    "\n",
    "# Iterate over each record\n",
    "for i in range(waveform_train.shape[0]):\n",
    "    # Iterate over each lead in the record\n",
    "    for j in range(waveform_train.shape[2]):\n",
    "        # Compute the minimum and maximum of the lead data\n",
    "        min_val = np.min(waveform_train[i, :, j])\n",
    "        max_val = np.max(waveform_train[i, :, j])\n",
    "\n",
    "        # Check if max_val equals to min_val\n",
    "        if max_val == min_val:\n",
    "            # If they are equal, then all the values are the same in this lead\n",
    "            # We can set the normalized values to 0 (or any constant value)\n",
    "            normalized_waveform_train[i, :, j] = 0\n",
    "        else:\n",
    "            # Perform normalization\n",
    "            normalized_waveform_train[i, :, j] = (waveform_train[i, :, j] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "344585ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15903308, 0.20707071, 0.73684211, ..., 0.31463415, 0.07619048,\n",
       "        0.10942761],\n",
       "       [0.15903308, 0.20707071, 0.73684211, ..., 0.31463415, 0.07619048,\n",
       "        0.10942761],\n",
       "       [0.15903308, 0.20707071, 0.73684211, ..., 0.31463415, 0.07619048,\n",
       "        0.10942761],\n",
       "       ...,\n",
       "       [0.2913486 , 0.20538721, 0.50877193, ..., 0.3597561 , 0.1031746 ,\n",
       "        0.27609428],\n",
       "       [0.22137405, 0.17845118, 0.59210526, ..., 0.35487805, 0.1       ,\n",
       "        0.26262626],\n",
       "       [0.22264631, 0.19191919, 0.60745614, ..., 0.35      , 0.1       ,\n",
       "        0.24915825]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_waveform_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdb9b3",
   "metadata": {},
   "source": [
    "## Initialize train dataloader ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d38a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = torch.from_numpy(normalized_waveform_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c20f3",
   "metadata": {},
   "source": [
    "visualization (not completely accurate) of waveform_data\n",
    "| Scaled Age | Male | Female | Device A | Device B | Validated True | Validated False |\n",
    "|------------|------|--------|----------|----------|----------------|-----------------|\n",
    "| -0.5       | 1    | 0      | 1        | 0        | 1              | 0               |\n",
    "| 1.2        | 0    | 1      | 0        | 1        | 0              | 1               |\n",
    "| -0.7       | 1    | 0      | 1        | 0        | 1              | 0               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2036ea",
   "metadata": {},
   "source": [
    "chatgpt rec\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#column-transformer-with-mixed-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ae1a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19601, 16])\n",
      "torch.Size([2198, 16])\n"
     ]
    }
   ],
   "source": [
    "#TODO: do y\n",
    "waveform_train = waveform_train.transpose(0, 2, 1)\n",
    "waveform_train = torch.from_numpy(waveform_train).float() \n",
    "\n",
    "metadata_train = torch.tensor(metadata_train, dtype=torch.float32)\n",
    "print(metadata_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "waveform_test = waveform_test.transpose(0, 2, 1)\n",
    "waveform_test = torch.from_numpy(waveform_test).float() \n",
    "\n",
    "metadata_test = torch.tensor(metadata_test, dtype=torch.float32)\n",
    "print(metadata_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bfb5d3",
   "metadata": {},
   "source": [
    "## Modeling ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976810d9",
   "metadata": {},
   "source": [
    "### CNN Autoencoder ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47e5382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=12,\n",
    "                      out_channels=32,\n",
    "                      kernel_size=5,\n",
    "                      stride=1),\n",
    "            nn.MaxPool1d(kernel_size=2, \n",
    "                         stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=5,\n",
    "                      stride=2),\n",
    "            nn.MaxPool1d(kernel_size=2, \n",
    "                         stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.MaxUnpool1d(kernel_size=2,\n",
    "                           stride=2),\n",
    "            nn.ConvTranspose1d(in_channels=64,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=5,\n",
    "                               stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxUnpool1d(kernel_size=2,\n",
    "                           stride=2),\n",
    "            nn.ConvTranspose1d(in_channels=32,\n",
    "                               out_channels=12,\n",
    "                               kernel_size=5,\n",
    "                               stride=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded_output = self.encoder(x)\n",
    "        decoded_output = self.decoder(encoded_output)\n",
    "        return decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e3040d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_cnn(model, train_loader, criterion, optimizer, nepoch=20):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on device: {device}\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(nepoch):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            waveforms = batch[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(waveforms)\n",
    "            loss = criterion(outputs, waveforms)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}')\n",
    "    \n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d463c1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n",
      "Epoch 1/10, Loss: 0.06751449070080848\n",
      "Epoch 2/10, Loss: 0.06752269406351724\n",
      "Epoch 3/10, Loss: 0.06752707451265944\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m CNNAutoencoder()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mtrain_model_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwaveform_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[53], line 21\u001b[0m, in \u001b[0;36mtrain_model_cnn\u001b[1;34m(model, train_waveform, epochs, batch_size)\u001b[0m\n\u001b[0;32m     17\u001b[0m waveforms \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#metadata = metadata.to(device)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#labels = labels.to(device)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, waveforms)\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[51], line 31\u001b[0m, in \u001b[0;36mCNNAutoencoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 31\u001b[0m     encoded_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     decoded_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(encoded_output)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoded_output\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model_cnn(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392bbb1a",
   "metadata": {},
   "source": [
    "### TCN Autoencoder ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9e9c6",
   "metadata": {},
   "source": [
    "Model Card for the Hybrid Autoencoder\n",
    "Model Name: Hybrid Autoencoder for ECG and Metadata\n",
    "\n",
    "Description: This model is designed to learn compressed representations of combined ECG waveform and patient metadata. It utilizes separate pathways for waveform data and metadata, merging them into a dense representation which is then used to reconstruct both types of data.\n",
    "\n",
    "Model Architecture:\n",
    "\n",
    "Waveform Pathway: Convolutional layers followed by pooling and flattening.\n",
    "Metadata Pathway: Dense layers.\n",
    "Combined Encoding and Decoding: Dense layers.\n",
    "Intended Use: Intended for anomaly detection in ECG data where additional patient metadata is available and considered relevant.\n",
    "\n",
    "Data Used for Training: Assumes a dataset comprising ECG waveform data aligned with patient metadata such as age, sex, and device information.\n",
    "\n",
    "Limitations: The model's effectiveness is highly dependent on the quality and preprocessing of the input data. The architecture needs fine-tuning and validation using real-world data to ensure robustness.\n",
    "\n",
    "Ethical Considerations: Care should be taken to avoid biases that may arise from imbalanced data across different demographic groups. Privacy concerns should be addressed when handling patient data.\n",
    "\n",
    "This framework sets up the foundation of your model; further tuning, training, and validation steps are needed to adapt it to specific tasks or datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tcn import TCN\n",
    "\n",
    "class TCNAutoencoder(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size, dropout, metadata_dims):\n",
    "        super(TCNAutoencoder, self).__init__()\n",
    "        self.encoder = TCN(\n",
    "            num_inputs=num_inputs,\n",
    "            num_channels=num_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            dropout=dropout,\n",
    "            causal=True,\n",
    "        )\n",
    "        self.age_embedding = nn.Embedding(120, metadata_dims[0])  # Assuming age range from 0 to 119\n",
    "        self.sex_embedding = nn.Embedding(2, metadata_dims[1])  # Assuming sex is binary (0 or 1)\n",
    "        self.device_embedding = nn.Embedding(num_devices, metadata_dims[2])  # num_devices is the number of unique devices\n",
    "        \n",
    "        decoder_input_dim = num_channels[-1] + sum(metadata_dims)\n",
    "        self.decoder = TCN(\n",
    "            num_inputs=decoder_input_dim,\n",
    "            num_channels=num_channels[::-1],\n",
    "            kernel_size=kernel_size,\n",
    "            dropout=dropout,    \n",
    "            causal=True,\n",
    "            output_projection=num_inputs,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, age, sex, device):\n",
    "        encoded = self.encoder(x)\n",
    "        \n",
    "        age_emb = self.age_embedding(age)\n",
    "        sex_emb = self.sex_embedding(sex)\n",
    "        device_emb = self.device_embedding(device)\n",
    "        \n",
    "        metadata_emb = torch.cat([age_emb, sex_emb, device_emb], dim=-1)\n",
    "        metadata_emb = metadata_emb.unsqueeze(2).expand(-1, -1, encoded.size(2))\n",
    "        \n",
    "        concatenated = torch.cat([encoded, metadata_emb], dim=1)\n",
    "        decoded = self.decoder(concatenated)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f90630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
