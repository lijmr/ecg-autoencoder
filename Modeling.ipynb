{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "126db5b6",
   "metadata": {},
   "source": [
    "# Modeling #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316c2a0",
   "metadata": {},
   "source": [
    "## Import APIs ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b05c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import wfdb\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7621688",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1acd02",
   "metadata": {},
   "source": [
    "## Load data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd8d169",
   "metadata": {},
   "source": [
    "### Metadata ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ced8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbxl_df = pd.read_csv('./cleaned_data/cleaned_ptbxl_metadata.csv', index_col='ecg_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2248b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>device</th>\n",
       "      <th>validated_by_human</th>\n",
       "      <th>diagnostic_superclass</th>\n",
       "      <th>strat_fold</th>\n",
       "      <th>filename_lr</th>\n",
       "      <th>filename_hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecg_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00001_lr</td>\n",
       "      <td>records500/00000/00001_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>2</td>\n",
       "      <td>records100/00000/00002_lr</td>\n",
       "      <td>records500/00000/00002_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>5</td>\n",
       "      <td>records100/00000/00003_lr</td>\n",
       "      <td>records500/00000/00003_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00004_lr</td>\n",
       "      <td>records500/00000/00004_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>4</td>\n",
       "      <td>records100/00000/00005_lr</td>\n",
       "      <td>records500/00000/00005_hr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  sex     device  validated_by_human diagnostic_superclass  \\\n",
       "ecg_id                                                                   \n",
       "1       56.0    1  CS-12   E                True              ['NORM']   \n",
       "2       19.0    0  CS-12   E                True              ['NORM']   \n",
       "3       37.0    1  CS-12   E                True              ['NORM']   \n",
       "4       24.0    0  CS-12   E                True              ['NORM']   \n",
       "5       19.0    1  CS-12   E                True              ['NORM']   \n",
       "\n",
       "        strat_fold                filename_lr                filename_hr  \n",
       "ecg_id                                                                    \n",
       "1                3  records100/00000/00001_lr  records500/00000/00001_hr  \n",
       "2                2  records100/00000/00002_lr  records500/00000/00002_hr  \n",
       "3                5  records100/00000/00003_lr  records500/00000/00003_hr  \n",
       "4                3  records100/00000/00004_lr  records500/00000/00004_hr  \n",
       "5                4  records100/00000/00005_lr  records500/00000/00005_hr  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptbxl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee970c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>device</th>\n",
       "      <th>validated_by_human</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecg_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  sex     device  validated_by_human\n",
       "ecg_id                                          \n",
       "1       56.0    1  CS-12   E                True\n",
       "2       19.0    0  CS-12   E                True\n",
       "3       37.0    1  CS-12   E                True\n",
       "4       24.0    0  CS-12   E                True\n",
       "5       19.0    1  CS-12   E                True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = ptbxl_df.loc[:, ['age', 'sex', 'device', 'validated_by_human']].copy()\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4c27e",
   "metadata": {},
   "source": [
    "### Waveform data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23d07cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21799, 1000, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# waveform_data = []\n",
    "# for idx in ptbxl_df.index:\n",
    "#     record_path = ptbxl_df.loc[idx]['filename_hr']\n",
    "#     waveform_df = pd.read_csv('./cleaned_data/waveform_data/' + record_path + '.csv', index_col='Time (s)')\n",
    "#     waveform_data.append(waveform_df)\n",
    "# waveform_data = np.array(waveform_data)\n",
    "# waveform_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a322ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_data = np.load(\"./cleaned_data/waveform_np.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c09649",
   "metadata": {},
   "source": [
    "## Create recommended train-test split ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ca5dc",
   "metadata": {},
   "source": [
    "This recommended train-test split code was obtained from the downloaded folder with the dataset: https://physionet.org/content/ptb-xl/1.0.3/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c74a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "test_fold = 10\n",
    "\n",
    "# Train\n",
    "waveform_train = waveform_data[np.where(ptbxl_df.strat_fold != test_fold)]\n",
    "metadata_train = metadata[ptbxl_df.strat_fold != test_fold]\n",
    "y_train = ptbxl_df[ptbxl_df.strat_fold != test_fold].diagnostic_superclass\n",
    "\n",
    "# Test\n",
    "waveform_test = waveform_data[np.where(ptbxl_df.strat_fold == test_fold)]\n",
    "metadata_test = metadata[ptbxl_df.strat_fold == test_fold]\n",
    "y_test = ptbxl_df[ptbxl_df.strat_fold == test_fold].diagnostic_superclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c04c2b",
   "metadata": {},
   "source": [
    "## Normalize waveform data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6065566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code generated from Bing Copilot\n",
    "normalized_waveform_train = np.empty_like(waveform_train)\n",
    "\n",
    "for i in range(waveform_train.shape[0]):\n",
    "    for j in range(waveform_train.shape[2]):\n",
    "        min_val = np.min(waveform_train[i, :, j])\n",
    "        max_val = np.max(waveform_train[i, :, j])\n",
    "\n",
    "        if max_val == min_val:\n",
    "            normalized_waveform_train[i, :, j] = 0\n",
    "        else:\n",
    "            normalized_waveform_train[i, :, j] = (waveform_train[i, :, j] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344585ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15903308, 0.20707071, 0.73684211, ..., 0.31463415, 0.07619048,\n",
       "        0.10942761],\n",
       "       [0.15903308, 0.20707071, 0.73684211, ..., 0.31463415, 0.07619048,\n",
       "        0.10942761],\n",
       "       [0.15903308, 0.20707071, 0.73684211, ..., 0.31463415, 0.07619048,\n",
       "        0.10942761],\n",
       "       ...,\n",
       "       [0.2913486 , 0.20538721, 0.50877193, ..., 0.3597561 , 0.1031746 ,\n",
       "        0.27609428],\n",
       "       [0.22137405, 0.17845118, 0.59210526, ..., 0.35487805, 0.1       ,\n",
       "        0.26262626],\n",
       "       [0.22264631, 0.19191919, 0.60745614, ..., 0.35      , 0.1       ,\n",
       "        0.24915825]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_waveform_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9b501",
   "metadata": {},
   "source": [
    "## Normalize and one-hot encode metadata ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a94634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tensors\n",
    "transformers = [\n",
    "    ('num', StandardScaler(), ['age']),\n",
    "    ('cat', OneHotEncoder(), ['sex', 'device', 'validated_by_human'])\n",
    "]\n",
    "\n",
    "ct = ColumnTransformer(transformers, remainder='passthrough')\n",
    "normalized_metadata_train = ct.fit_transform(metadata_train)\n",
    "\n",
    "# Make dense array\n",
    "normalized_metadata_train  = normalized_metadata_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d29687e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.205340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.358430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.797467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.202607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.358430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19596</th>\n",
       "      <td>0.137470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19597</th>\n",
       "      <td>7.398818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19598</th>\n",
       "      <td>-0.111847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19599</th>\n",
       "      <td>0.043976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19600</th>\n",
       "      <td>0.168635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19601 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1    2    3    4    5    6    7    8    9    10   11   12  \\\n",
       "0     -0.205340  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1     -1.358430  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2     -0.797467  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3     -1.202607  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "4     -1.358430  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "19596  0.137470  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "19597  7.398818  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "19598 -0.111847  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "19599  0.043976  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "19600  0.168635  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "\n",
       "        13   14   15  \n",
       "0      0.0  0.0  1.0  \n",
       "1      0.0  0.0  1.0  \n",
       "2      0.0  0.0  1.0  \n",
       "3      0.0  0.0  1.0  \n",
       "4      0.0  0.0  1.0  \n",
       "...    ...  ...  ...  \n",
       "19596  0.0  0.0  1.0  \n",
       "19597  0.0  0.0  1.0  \n",
       "19598  0.0  0.0  1.0  \n",
       "19599  0.0  0.0  1.0  \n",
       "19600  0.0  0.0  1.0  \n",
       "\n",
       "[19601 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(normalized_metadata_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdb9b3",
   "metadata": {},
   "source": [
    "## Initialize train dataloader ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ae1a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do y\n",
    "# normalized_waveform_train = torch.from_numpy(normalized_waveform_train)\n",
    "# normalized_waveform_train = normalized_waveform_train.permute(0, 2, 1)\n",
    "# print(normalized_waveform_train.shape)\n",
    "\n",
    "# normalized_metadata_train = torch.tensor(normalized_metadata_train, dtype=torch.float32)\n",
    "# print(normalized_metadata_train.shape)\n",
    "\n",
    "# waveform_test = torch.tensor(waveform_test).float() \n",
    "# waveform_test = waveform_test.permute(0, 2, 1)\n",
    "\n",
    "# metadata_test = torch.tensor(normalized_metadata_test, dtype=torch.float32)\n",
    "# print(metadata_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd869284",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = TensorDataset(torch.from_numpy(normalized_waveform_train).float(), torch.from_numpy(normalized_metadata_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976810d9",
   "metadata": {},
   "source": [
    "## CNN autoencoder + LSTM metadata model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47e5382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=12,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=5,\n",
    "                      stride=1),\n",
    "            nn.MaxPool1d(kernel_size=2, \n",
    "                         stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=128,\n",
    "                               out_channels=12,\n",
    "                               kernel_size=5,\n",
    "                               stride=1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Upsample(size=1000)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded_output = self.encoder(x)\n",
    "        decoded_output = self.decoder(encoded_output)\n",
    "        return decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60308ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(16, 32, batch_first=True)\n",
    "        self.output_layer = nn.Linear(32, 16)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        lstm_outputs, h_n = self.lstm(x, h)\n",
    "        outputs = self.output_layer(lstm_outputs)\n",
    "        return outputs, h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "834c1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, cnn_autoencoder, lstm_model):\n",
    "        super().__init__()\n",
    "        self.cnn_autoencoder = cnn_autoencoder\n",
    "        self.lstm_model = lstm_model\n",
    "        self.fc = nn.Linear(12 + 16, 12)\n",
    "        \n",
    "    def forward(self, ecg_data, metadata, hc):\n",
    "        cnn_output = self.cnn_autoencoder(ecg_data)\n",
    "        lstm_outputs, hc_n = self.lstm_model(metadata, hc)\n",
    "\n",
    "        # Reshape cnn_output and extract the last output from lstm_outputs\n",
    "        cnn_output = cnn_output.view(cnn_output.size(0), -1)\n",
    "        lstm_last_output = lstm_outputs[:, -1, :]\n",
    "        \n",
    "        combined_output = torch.cat((cnn_output, lstm_last_output), dim=1)\n",
    "        output = self.fc(combined_output)\n",
    "\n",
    "        return output, hc_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f47c0",
   "metadata": {},
   "source": [
    "### Training ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "744f0179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedModel(\n",
       "  (cnn_autoencoder): CNNAutoencoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Conv1d(12, 128, kernel_size=(5,), stride=(1,))\n",
       "      (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): ConvTranspose1d(128, 12, kernel_size=(5,), stride=(1,))\n",
       "      (1): Sigmoid()\n",
       "      (2): Upsample(size=1000, mode='nearest')\n",
       "    )\n",
       "  )\n",
       "  (lstm_model): MetadataLSTM(\n",
       "    (lstm): LSTM(16, 32, batch_first=True)\n",
       "    (output_layer): Linear(in_features=32, out_features=16, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=28, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_autoencoder_model = CNNAutoencoder()\n",
    "lstm_metadata_model = MetadataLSTM()\n",
    "\n",
    "combinedModel = CombinedModel(cnn_autoencoder_model, lstm_metadata_model)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(combinedModel.parameters(), lr=1e-3)\n",
    "\n",
    "combinedModel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e3040d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_combined(model, train_loader, criterion, optimizer, nepoch=10):\n",
    "    for epoch in range(nepoch):\n",
    "        for batch_data, batch_metadata in train_loader:\n",
    "            ecg_data = batch_data.to(device).permute(0, 2, 1).float()\n",
    "            batch_metadata = batch_metadata.to(device).float()\n",
    "            \n",
    "            #reshape for lstm\n",
    "            batch_metadata = batch_metadata.view(batch_metadata.size(0), -1, 16)\n",
    "        \n",
    "            num_layers = model.lstm_model.lstm.num_layers\n",
    "            hidden_size = model.lstm_model.lstm.hidden_size\n",
    "            h_0 = torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "            c_0 = torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            reconstructed_data, (h_n, c_n) = model(ecg_data, batch_metadata, (h_0, c_0))\n",
    "            loss = criterion(reconstructed_data, ecg_data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{nepoch}], Loss: {loss.item():.4f}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d463c1bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x12016 and 28x12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_combined\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombinedModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 16\u001b[0m, in \u001b[0;36mtrain_combined\u001b[1;34m(model, train_loader, criterion, optimizer, nepoch)\u001b[0m\n\u001b[0;32m     13\u001b[0m c_0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(num_layers, batch_size, hidden_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 16\u001b[0m reconstructed_data, (h_n, c_n) \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mecg_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(reconstructed_data, ecg_data)\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 17\u001b[0m, in \u001b[0;36mCombinedModel.forward\u001b[1;34m(self, ecg_data, metadata, hc)\u001b[0m\n\u001b[0;32m     14\u001b[0m lstm_last_output \u001b[38;5;241m=\u001b[39m lstm_outputs[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     16\u001b[0m combined_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((cnn_output, lstm_last_output), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, hc_n\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x12016 and 28x12)"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_combined(combinedModel, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d5e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "torch.save(cnn_autoencoder_model.state_dict(), \"./models/cnn_autoencoder.pth\")\n",
    "print(f\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1776046",
   "metadata": {},
   "source": [
    "### Plotting ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(waveform_df, segment_length=1000, start_index=0):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for col in waveform_df.columns:\n",
    "        plt.plot(waveform_df.index, waveform_df[col], label=f'Lead {col}')\n",
    "    \n",
    "    plt.title('ECG Waveform')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f90630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "392bbb1a",
   "metadata": {},
   "source": [
    "## TCN Autoencoder ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb809b3d",
   "metadata": {},
   "source": [
    "Model Card for the Hybrid Autoencoder Model Name: Hybrid Autoencoder for ECG and Metadata\n",
    "\n",
    "Description: This model is designed to learn compressed representations of combined ECG waveform and patient metadata. It utilizes separate pathways for waveform data and metadata, merging them into a dense representation which is then used to reconstruct both types of data.\n",
    "\n",
    "Model Architecture:\n",
    "\n",
    "Waveform Pathway: Convolutional layers followed by pooling and flattening. Metadata Pathway: Dense layers. Combined Encoding and Decoding: Dense layers. Intended Use: Intended for anomaly detection in ECG data where additional patient metadata is available and considered relevant.\n",
    "\n",
    "Data Used for Training: Assumes a dataset comprising ECG waveform data aligned with patient metadata such as age, sex, and device information.\n",
    "\n",
    "Limitations: The model's effectiveness is highly dependent on the quality and preprocessing of the input data. The architecture needs fine-tuning and validation using real-world data to ensure robustness.\n",
    "\n",
    "Ethical Considerations: Care should be taken to avoid biases that may arise from imbalanced data across different demographic groups. Privacy concerns should be addressed when handling patient data.\n",
    "\n",
    "This framework sets up the foundation of your model; further tuning, training, and validation steps are needed to adapt it to specific tasks or datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76f9a2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique devices: 11\n"
     ]
    }
   ],
   "source": [
    "num_unique_devices = metadata['device'].nunique()\n",
    "print(f\"Number of unique devices: {num_unique_devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843f9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tcn import TCN\n",
    "\n",
    "class TCNAutoencoder(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size, dropout, metadata_dims):\n",
    "        super(TCNAutoencoder, self).__init__()\n",
    "        self.encoder = TCN(\n",
    "            num_inputs=num_inputs,\n",
    "            num_channels=num_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            dropout=dropout,\n",
    "            causal=True,\n",
    "        )\n",
    "        self.age_embedding = nn.Linear(1, metadata_dims[0])  # Age is a single value\n",
    "        self.sex_embedding = nn.Linear(2, metadata_dims[1])  # Sex is one-hot encoded (2 columns)\n",
    "        self.device_embedding = nn.Linear(num_unique_devices, metadata_dims[2]) #one hot (11 cols)\n",
    "        self.validated_embedding = nn.Linear(2, metadata_dims[3]) #one hot (2 cols)\n",
    "        \n",
    "        decoder_input_dim = num_channels[-1] + sum(metadata_dims)\n",
    "        self.decoder = TCN(\n",
    "            num_inputs=decoder_input_dim,\n",
    "            num_channels=num_channels[::-1],\n",
    "            kernel_size=kernel_size,\n",
    "            dropout=dropout,    \n",
    "            causal=True,\n",
    "            output_projection=num_inputs,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, metadata):\n",
    "        encoded = self.encoder(x)\n",
    "        \n",
    "        age_emb = self.age_embedding(metadata[:, 0].unsqueeze(1))\n",
    "        sex_emb = self.sex_embedding(metadata[:, 1:3])\n",
    "        device_emb = self.device_embedding(metadata[:, 3:-2])\n",
    "        validated_emb = self.validated_embedding(metadata[:, -2:])\n",
    "        \n",
    "        metadata_emb = torch.cat([age_emb, sex_emb, device_emb, validated_emb], dim=-1)\n",
    "        metadata_emb = metadata_emb.unsqueeze(2).expand(-1, -1, encoded.size(2))\n",
    "        \n",
    "        concatenated = torch.cat([encoded, metadata_emb], dim=1)\n",
    "        decoded = self.decoder(concatenated)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39f90630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19601, 16)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_inputs = 12  # Assuming 12 input channels in the ECG data\n",
    "num_channels = [32, 64, 128]  # Example number of channels in each residual block of the encoder\n",
    "kernel_size = 3  # Example kernel size for the TCN layers\n",
    "dropout = 0.2  # Example dropout rate\n",
    "metadata_dims = [10, 5, 20, 5]  # Example embedding dimensions for age, sex, and device\n",
    "\n",
    "num_unique_devices = metadata['device'].nunique()\n",
    "print(normalized_metadata_train.shape)\n",
    "assert num_unique_devices == normalized_metadata_train.shape[1] - 5, \"Number of unique devices should match the number of device columns in metadata\"\n",
    "\n",
    "model = TCNAutoencoder(num_inputs, num_channels, kernel_size, dropout, metadata_dims)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(normalized_waveform_train).float(), torch.from_numpy(normalized_metadata_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c798882b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0011\n",
      "Epoch [2/10], Loss: 0.0003\n",
      "Epoch [3/10], Loss: 0.0002\n",
      "Epoch [4/10], Loss: 0.0001\n",
      "Epoch [5/10], Loss: 0.0001\n",
      "Epoch [6/10], Loss: 0.0000\n",
      "Epoch [7/10], Loss: 0.0001\n",
      "Epoch [8/10], Loss: 0.0000\n",
      "Epoch [9/10], Loss: 0.0000\n",
      "Epoch [10/10], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_data, batch_metadata in train_loader:\n",
    "        ecg_data = batch_data.to(device).permute(0, 2, 1).float()\n",
    "        batch_metadata = batch_metadata.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        reconstructed_data = model(ecg_data, batch_metadata)\n",
    "        loss = criterion(reconstructed_data, ecg_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e71fc6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"./models/tcn.pth\")\n",
    "print(f\"Model saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
