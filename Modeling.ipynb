{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "126db5b6",
   "metadata": {},
   "source": [
    "# Modeling #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316c2a0",
   "metadata": {},
   "source": [
    "## Import APIs ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b05c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import wfdb\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7621688",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1acd02",
   "metadata": {},
   "source": [
    "## Load data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a211c406",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ptbxl_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ptbxl_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./cleaned_data/cleaned_ptbxl_metadata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecg_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m normal_data \u001b[38;5;241m=\u001b[39m ptbxl_data[ptbxl_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagnostic_superclass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNORMAL\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m abnormal_data \u001b[38;5;241m=\u001b[39m ptbxl_data[ptbxl_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagnostic_superclass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mABNORMAL\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ptbxl_df' is not defined"
     ]
    }
   ],
   "source": [
    "ptbxl_data = pd.read_csv('./cleaned_data/cleaned_ptbxl_metadata.csv', index_col='ecg_id')\n",
    "normal_data = ptbxl_data[ptbxl_data['diagnostic_superclass'] == 'NORMAL']\n",
    "abnormal_data = ptbxl_data[ptbxl_data['diagnostic_superclass'] == 'ABNORMAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd8d169",
   "metadata": {},
   "source": [
    "### Metadata ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1464b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_metadata = normal_data.loc[:, ['age', 'sex', 'device', 'validated_by_human']].copy()\n",
    "abnormal_metadata = abnormal_data.loc[:, ['age', 'sex', 'device', 'validated_by_human']].copy()\n",
    "print(f'Normal metadata shape: {normal_metadata.shape}')\n",
    "print(f'Abnormal metadata shape: {abnormal_metadata.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4c27e",
   "metadata": {},
   "source": [
    "### ECG Waveform data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d07cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_ecg_data(data):\n",
    "    new_data = []\n",
    "    for idx in data.index:\n",
    "        record_path = data.loc[idx]['filename_hr']\n",
    "        waveform_df = pd.read_csv('./cleaned_data/waveform_data/' + record_path + '.csv', index_col='Time (s)')\n",
    "        new_data.append(waveform_df)\n",
    "    new_data = np.array(new_data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_ecg_data = extract_ecg_data(normal_data)\n",
    "abnormal_ecg_data = extract_ecg_data(abnormal_data)\n",
    "print(f'Normal ECG data shape: {normal_ecg_data.shape}')\n",
    "print(f'Abnormal ECG data shape: {abnormal_ecg_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform_data = np.load(\"./cleaned_data/waveform_np.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c5640",
   "metadata": {},
   "source": [
    "## Train-test split ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ca5dc",
   "metadata": {},
   "source": [
    "This recommended train-test split code was obtained from the downloaded folder with the dataset: https://physionet.org/content/ptb-xl/1.0.3/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c74a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(normal_data.shape[0] * 0.8)\n",
    "\n",
    "normal_ecg_train = normal_ecg_data[0:split_idx]\n",
    "normal_ecg_test = normal_ecg_data[split_idx:]\n",
    "print(f'Normal ECG train shape: {normal_ecg_train.shape}')\n",
    "print(f'Normal ECG test shape: {normal_ecg_test.shape}')\n",
    "\n",
    "abnormal_ecg_train = abnormal_ecg_data[0:split_idx]\n",
    "abnormal_ecg_test = abnormal_ecg_data[split_idx:]\n",
    "print(f'Abnormal ECG train shape: {abnormal_ecg_train.shape}')\n",
    "print(f'Abnormal ECG test shape: {abnormal_ecg_test.shape}')\n",
    "\n",
    "normal_metadata_train = normal_metadata[0:split_idx]\n",
    "normal_metadata_test = normal_metadata[split_idx:]\n",
    "print(f'Normal metadata train shape: {normal_metadata_train.shape}')\n",
    "print(f'Normal metadata test shape: {normal_metadata_test.shape}')\n",
    "\n",
    "abnormal_metadata_train = abnormal_metadata[0:split_idx]\n",
    "abnormal_metadata_test = abnormal_metadata[split_idx:]\n",
    "print(f'Abnormal metadata train shape: {abnormal_metadata_train.shape}')\n",
    "print(f'Abnormal metadata test shape: {abnormal_metadata_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c04c2b",
   "metadata": {},
   "source": [
    "## Normalize ECG waveform data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6065566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_waveform(data):\n",
    "    # Code generated from Bing Copilot\n",
    "    normalized_data = np.empty_like(data)\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[2]):\n",
    "            min_val = np.min(data[i, :, j])\n",
    "            max_val = np.max(data[i, :, j])\n",
    "\n",
    "            if max_val == min_val:\n",
    "                normalized_data[i, :, j] = 0\n",
    "            else:\n",
    "                normalized_data[i, :, j] = (data[i, :, j] - min_val) / (max_val - min_val)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344585ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Since normalization occurs only within each record, there will be no contamination from train data\n",
    "std_normal_ecg_train = normalize_waveform(normal_ecg_train)\n",
    "std_normal_ecg_test = normalize_waveform(normal_ecg_test)\n",
    "\n",
    "std_abnormal_ecg_train = normalize_waveform(abnormal_ecg_train)\n",
    "std_abnormal_ecg_test = normalize_waveform(abnormal_ecg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9b501",
   "metadata": {},
   "source": [
    "## Normalize and one-hot encode metadata ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a94634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code generated from ChatGPT\n",
    "scaler_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "encoder_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "normal_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler_transformer, ['age']),\n",
    "        ('cat', encoder_transformer, ['sex', 'device', 'validated_by_human'])\n",
    "    ])\n",
    "\n",
    "std_normal_metadata_train = normal_preprocessor.fit_transform(normal_metadata_train).toarray()\n",
    "std_normal_metadata_test = normal_preprocessor.transform(normal_metadata_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81911d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "encoder_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "abnormal_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler_transformer, ['age']),\n",
    "        ('cat', encoder_transformer, ['sex', 'device', 'validated_by_human'])\n",
    "    ])\n",
    "\n",
    "std_abnormal_metadata_train = abnormal_preprocessor.fit_transform(abnormal_metadata_train).toarray()\n",
    "std_abnormal_metadata_test = abnormal_preprocessor.transform(abnormal_metadata_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdb9b3",
   "metadata": {},
   "source": [
    "## Initialize Autoencoder Dataloaders ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f16bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_ecg_train_set = torch.from_numpy(std_normal_ecg_train).float()\n",
    "autoencoder_metadata_train_set = torch.from_numpy(std_normal_metadata_train).float()\n",
    "\n",
    "normal_ecg_test_set = torch.from_numpy(std_normal_ecg_test).float()\n",
    "normal_metadata_test_set = torch.from_numpy(std_normal_metadata_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd869284",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "autoencoder_train_dataset = TensorDataset(autoencoder_ecg_train_set, autoencoder_metadata_train_set)\n",
    "autoencoder_train_loader = DataLoader(autoencoder_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "autoencoder_test_dataset = TensorDataset(normal_ecg_test_set, normal_metadata_test_set)\n",
    "autoencoder_test_loader = DataLoader(autoencoder_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976810d9",
   "metadata": {},
   "source": [
    "## CNN autoencoder + LSTM metadata model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e5382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=12,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=4,\n",
    "                      stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=64,\n",
    "                               out_channels=12,\n",
    "                               kernel_size=4,\n",
    "                               stride=1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Upsample(1000)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        encoded_output = self.encoder(x)\n",
    "        decoded_output = self.decoder(encoded_output)\n",
    "        return decoded_output.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60308ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(16, 64, batch_first=True)\n",
    "        self.output_layer = nn.Linear(64, 12)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        lstm_outputs, h_n = self.lstm(x, h)\n",
    "        outputs = self.output_layer(lstm_outputs.squeeze(dim=1))\n",
    "        return outputs, h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, cnn_autoencoder, lstm_model):\n",
    "        super().__init__()\n",
    "        self.cnn_autoencoder = cnn_autoencoder\n",
    "        self.lstm_model = lstm_model\n",
    "        self.fc = nn.Linear(24, 12)\n",
    "        \n",
    "    def forward(self, ecg_data, metadata, hc):\n",
    "        cnn_output = self.cnn_autoencoder(ecg_data)\n",
    "        lstm_output, hc_n = self.lstm_model(metadata, hc)\n",
    "        reshaped_lstm_output = lstm_output.unsqueeze(1).repeat(1, 1000, 1)\n",
    "        combined_output = torch.cat((cnn_output, reshaped_lstm_output), dim=-1)\n",
    "        output = self.fc(combined_output)\n",
    "\n",
    "        return output, hc_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f47c0",
   "metadata": {},
   "source": [
    "### Training ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_autoencoder_model = CNNAutoencoder()\n",
    "lstm_metadata_model = MetadataLSTM()\n",
    "\n",
    "combinedModel = CombinedModel(cnn_autoencoder_model, lstm_metadata_model)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(combinedModel.parameters(), lr=1e-3)\n",
    "\n",
    "combinedModel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3040d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_combined(model, train_loader, criterion, optimizer, nepoch=10):\n",
    "    for epoch in range(nepoch):\n",
    "        num_layers = model.lstm_model.lstm.num_layers\n",
    "        hidden_size = model.lstm_model.lstm.hidden_size\n",
    "        h_0 = torch.zeros(num_layers, hidden_size).to(device)\n",
    "        c_0 = torch.zeros(num_layers, hidden_size).to(device)\n",
    "        for batch_ecg, batch_metadata in train_loader:\n",
    "            ecg_data = batch_ecg.to(device).float()\n",
    "            metadata = batch_metadata.to(device).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            reconstructed_data, (h_n, c_n) = model(ecg_data, metadata, (h_0, c_0))\n",
    "            loss = criterion(reconstructed_data, ecg_data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{nepoch}], Loss: {loss.item()}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d463c1bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_combined(combinedModel, autoencoder_train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(combinedModel.state_dict(), \"./models/combinedModel.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1776046",
   "metadata": {},
   "source": [
    "### Visualization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, ecg_input, metadata_input):\n",
    "    lead_vals = ['I', 'II', 'III', 'AVR', 'AVL', 'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "    time = np.arange(0, 1000) / 100\n",
    "    \n",
    "    num_layers = model.lstm_model.lstm.num_layers\n",
    "    hidden_size = model.lstm_model.lstm.hidden_size\n",
    "    h_0 = torch.zeros(num_layers, hidden_size).to(device)\n",
    "    c_0 = torch.zeros(num_layers, hidden_size).to(device)\n",
    "    \n",
    "    prediction, _ = model(ecg_input, metadata_input, (h_0, c_0))\n",
    "    fig, axs = plt.subplots(6, 2, figsize=(15, 20))\n",
    "    for i in range(6):\n",
    "        for j in range(2):\n",
    "            lead_idx = i * 2 + j\n",
    "            lead_val = lead_vals[lead_idx]\n",
    "            \n",
    "            original_ecg = ecg_input[0, :, lead_idx].detach().numpy()\n",
    "            reconstructed_ecg = prediction[0, :, lead_idx].detach().numpy()\n",
    "            \n",
    "            axs[i, j].plot(time, original_ecg, label='Original')\n",
    "            axs[i, j].plot(time, reconstructed_ecg, label='Reconstructed')\n",
    "            axs[i, j].set_xlabel('Time (s)')\n",
    "            axs[i, j].set_ylabel('Normalized ECG Reading')\n",
    "            axs[i, j].set_title(f'Lead {lead_val}')\n",
    "            axs[i, j].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f90630",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_data, batch_metadata in test_loader:\n",
    "    ecg_data = batch_data.to(device).float()\n",
    "    batch_size = ecg_data.size(0)\n",
    "    batch_metadata = batch_metadata.to(device).float()\n",
    "    \n",
    "    single_ecg_data = ecg_data[0].unsqueeze(0)\n",
    "    single_metadata = batch_metadata[0].unsqueeze(0)\n",
    "    \n",
    "    break\n",
    "\n",
    "visualize_predictions(combinedModel, single_ecg_data, single_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f936575d",
   "metadata": {},
   "source": [
    "# Computational Experiment #1: Transfer Learning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392bbb1a",
   "metadata": {},
   "source": [
    "# Computational Experiment #2:  TCN Autoencoder #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a5d2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb809b3d",
   "metadata": {},
   "source": [
    "Model Card for the Hybrid Autoencoder Model Name: Hybrid Autoencoder for ECG and Metadata\n",
    "\n",
    "Description: This model is designed to learn compressed representations of combined ECG waveform and patient metadata. It utilizes separate pathways for waveform data and metadata, merging them into a dense representation which is then used to reconstruct both types of data.\n",
    "\n",
    "Model Architecture:\n",
    "\n",
    "Waveform Pathway: Convolutional layers followed by pooling and flattening. Metadata Pathway: Dense layers. Combined Encoding and Decoding: Dense layers. Intended Use: Intended for anomaly detection in ECG data where additional patient metadata is available and considered relevant.\n",
    "\n",
    "Data Used for Training: Assumes a dataset comprising ECG waveform data aligned with patient metadata such as age, sex, and device information.\n",
    "\n",
    "Limitations: The model's effectiveness is highly dependent on the quality and preprocessing of the input data. The architecture needs fine-tuning and validation using real-world data to ensure robustness.\n",
    "\n",
    "Ethical Considerations: Care should be taken to avoid biases that may arise from imbalanced data across different demographic groups. Privacy concerns should be addressed when handling patient data.\n",
    "\n",
    "This framework sets up the foundation of your model; further tuning, training, and validation steps are needed to adapt it to specific tasks or datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_devices = metadata['device'].nunique()\n",
    "print(f\"Number of unique devices: {num_unique_devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tcn import TCN\n",
    "num_unique_devices = metadata['device'].nunique()\n",
    "class TCNAutoencoder(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size, dropout, metadata_dims):\n",
    "        super(TCNAutoencoder, self).__init__()\n",
    "        self.encoder = TCN(\n",
    "            num_inputs=num_inputs,\n",
    "            num_channels=num_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            dropout=dropout,\n",
    "            causal=True,\n",
    "        )\n",
    "        self.age_embedding = nn.Linear(1, metadata_dims[0])  # Age is a single value\n",
    "        self.sex_embedding = nn.Linear(2, metadata_dims[1])  # Sex is one-hot encoded (2 columns)\n",
    "        self.device_embedding = nn.Linear(num_unique_devices, metadata_dims[2]) #one hot (11 cols)\n",
    "        self.validated_embedding = nn.Linear(2, metadata_dims[3]) #one hot (2 cols)\n",
    "        \n",
    "        decoder_input_dim = num_channels[-1] + sum(metadata_dims)\n",
    "        self.decoder = TCN(\n",
    "            num_inputs=decoder_input_dim,\n",
    "            num_channels=num_channels[::-1],\n",
    "            kernel_size=kernel_size,\n",
    "            dropout=dropout,    \n",
    "            causal=True,\n",
    "            output_projection=num_inputs,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, metadata):\n",
    "        encoded = self.encoder(x)\n",
    "        \n",
    "        age_emb = self.age_embedding(metadata[:, 0].unsqueeze(1))\n",
    "        sex_emb = self.sex_embedding(metadata[:, 1:3])\n",
    "        device_emb = self.device_embedding(metadata[:, 3:-2])\n",
    "        validated_emb = self.validated_embedding(metadata[:, -2:])\n",
    "        \n",
    "        metadata_emb = torch.cat([age_emb, sex_emb, device_emb, validated_emb], dim=-1)\n",
    "        metadata_emb = metadata_emb.unsqueeze(2).expand(-1, -1, encoded.size(2))\n",
    "        \n",
    "        concatenated = torch.cat([encoded, metadata_emb], dim=1)\n",
    "        decoded = self.decoder(concatenated)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e042cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_inputs = 12  # Assuming 12 input channels in the ECG data\n",
    "num_channels = [32, 64, 128]  # Example number of channels in each residual block of the encoder\n",
    "kernel_size = 3  # Example kernel size for the TCN layers\n",
    "dropout = 0.2  # Example dropout rate\n",
    "metadata_dims = [10, 5, 20, 5]  # Example embedding dimensions for age, sex, and device, and validated\n",
    "\n",
    "num_unique_devices = metadata['device'].nunique()\n",
    "print(normalized_metadata_train.shape)\n",
    "assert num_unique_devices == normalized_metadata_train.shape[1] - 5, \"Number of unique devices should match the number of device columns in metadata\"\n",
    "\n",
    "model = TCNAutoencoder(num_inputs, num_channels, kernel_size, dropout, metadata_dims)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "#train_dataset = TensorDataset(torch.from_numpy(normalized_waveform_train).float(), torch.from_numpy(normalized_metadata_train))\n",
    "train_loader = DataLoader(wave, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_data, batch_metadata in train_loader:\n",
    "        ecg_data = batch_data.to(device).permute(0, 2, 1).float()\n",
    "        batch_metadata = batch_metadata.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        reconstructed_data = model(ecg_data, batch_metadata)\n",
    "        loss = criterion(reconstructed_data, ecg_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71fc6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./models/tcn.pth\")\n",
    "print(f\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2379ed25",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/tcn.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     10\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 13\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform_test_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_test_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\utils\\data\\dataset.py:202\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[1;31mAssertionError\u001b[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_inputs = 12  # Assuming 12 input channels in the ECG data\n",
    "num_channels = [32, 64, 128]  # Example number of channels in each residual block of the encoder\n",
    "kernel_size = 3  # Example kernel size for the TCN layers\n",
    "dropout = 0.2  # Example dropout rate\n",
    "metadata_dims = [10, 5, 20, 5]  # Example embedding dimensions for age, sex, and device, and validated\n",
    "\n",
    "loaded_model = TCNAutoencoder(num_inputs, num_channels, kernel_size, dropout, metadata_dims)\n",
    "loaded_model.load_state_dict(torch.load(\"./models/tcn.pth\"))\n",
    "loaded_model.to(device)\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(waveform_test_set.float(), metadata_test_set)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_metadata in test_loader:\n",
    "            ecg_data = batch_data.to(device).permute(0, 2, 1).float()\n",
    "            batch_metadata = batch_metadata.to(device).float()\n",
    "            reconstructed_data = model(ecg_data, batch_metadata)\n",
    "            loss = criterion(reconstructed_data, ecg_data)\n",
    "            test_loss += loss.item()\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21684fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(loaded_model, test_loader, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
