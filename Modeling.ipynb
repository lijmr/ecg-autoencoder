{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "126db5b6",
   "metadata": {},
   "source": [
    "# Modeling #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316c2a0",
   "metadata": {},
   "source": [
    "## Import APIs ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89b05c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import wfdb\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1acd02",
   "metadata": {},
   "source": [
    "## Load data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd8d169",
   "metadata": {},
   "source": [
    "### Metadata ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3ced8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbxl_df = pd.read_csv('./cleaned_data/cleaned_ptbxl_metadata.csv', index_col='ecg_id')\n",
    "metadata = ptbxl_df.loc[:, ['age', 'sex', 'device', 'validated_by_human']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4c27e",
   "metadata": {},
   "source": [
    "### Waveform data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23d07cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21799, 1000, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_data = []\n",
    "for idx in ptbxl_df.index:\n",
    "    record_path = ptbxl_df.loc[idx]['filename_hr']\n",
    "    waveform_df = pd.read_csv('./cleaned_data/waveform_data/' + record_path + '.csv', index_col='Time (s)')\n",
    "    waveform_data.append(waveform_df)\n",
    "waveform_data = np.array(waveform_data)\n",
    "waveform_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a322ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform_data = np.load(\"./cleaned_data/waveform_np.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c09649",
   "metadata": {},
   "source": [
    "## Create recommended train-test split ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ca5dc",
   "metadata": {},
   "source": [
    "This recommended train-test split code was obtained from the downloaded folder with the dataset: https://physionet.org/content/ptb-xl/1.0.3/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11c74a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "test_fold = 10\n",
    "\n",
    "# Train\n",
    "waveform_train = waveform_data[np.where(ptbxl_df.strat_fold != test_fold)]\n",
    "metadata_train = metadata[ptbxl_df.strat_fold != test_fold]\n",
    "y_train = ptbxl_df[ptbxl_df.strat_fold != test_fold].diagnostic_superclass\n",
    "\n",
    "# Test\n",
    "waveform_test = waveform_data[np.where(ptbxl_df.strat_fold == test_fold)]\n",
    "metadata_test = metadata[ptbxl_df.strat_fold == test_fold]\n",
    "y_test = ptbxl_df[ptbxl_df.strat_fold == test_fold].diagnostic_superclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c04c2b",
   "metadata": {},
   "source": [
    "## Normalize waveform data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6065566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_waveform(waveform_data):\n",
    "    # Code generated from Bing Copilot\n",
    "    normalized_data = np.empty_like(waveform_train)\n",
    "    for i in range(waveform_data.shape[0]):\n",
    "        for j in range(waveform_data.shape[2]):\n",
    "            min_val = np.min(waveform_data[i, :, j])\n",
    "            max_val = np.max(waveform_data[i, :, j])\n",
    "\n",
    "            if max_val == min_val:\n",
    "                normalized_data[i, :, j] = 0\n",
    "            else:\n",
    "                normalized_data[i, :, j] = (waveform_data[i, :, j] - min_val) / (max_val - min_val)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21ebf264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since normalization occurs only within each record, there will be no contamination from train data\n",
    "normalized_waveform_train = normalize_waveform(waveform_train)\n",
    "normalized_waveform_test = normalize_waveform(waveform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9b501",
   "metadata": {},
   "source": [
    "## Normalize and one-hot encode metadata ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70a94634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code generated from ChatGPT\n",
    "scaler_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "encoder_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler_transformer, ['age']),\n",
    "        ('cat', encoder_transformer, ['sex', 'device', 'validated_by_human'])\n",
    "    ])\n",
    "\n",
    "normalized_metadata_train = preprocessor.fit_transform(metadata_train).toarray()\n",
    "normalized_metadata_test = preprocessor.transform(metadata_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdb9b3",
   "metadata": {},
   "source": [
    "## Initialize Dataloaders ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6f16bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_train_set = torch.from_numpy(normalized_waveform_train)\n",
    "waveform_test_set = torch.from_numpy(normalized_waveform_test)\n",
    "\n",
    "metadata_train_set = torch.from_numpy(normalized_metadata_train)\n",
    "metadata_test_set = torch.from_numpy(normalized_metadata_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd869284",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "waveform_train_loader = DataLoader(waveform_train_set, batch_size=batch_size)\n",
    "waveform_test_loader = DataLoader(waveform_test_set, batch_size=batch_size)\n",
    "\n",
    "metadata_train_loader = DataLoader(metadata_train_set, batch_size=batch_size)\n",
    "metadata_test_loader = DataLoader(metadata_test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976810d9",
   "metadata": {},
   "source": [
    "## CNN autoencoder + LSTM metadata model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47e5382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=12,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=5,\n",
    "                      stride=1),\n",
    "            nn.MaxPool1d(kernel_size=2, \n",
    "                         stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=128,\n",
    "                               out_channels=12,\n",
    "                               kernel_size=5,\n",
    "                               stride=1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Upsample(size=1000)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded_output = self.encoder(x)\n",
    "        decoded_output = self.decoder(encoded_output)\n",
    "        return decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60308ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(16, 32)\n",
    "        self.output_layer = nn.Linear(32, 16)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        lstm_outputs, h_n = self.lstm(x, h)\n",
    "        outputs = self.output_layer(lstm_outputs)\n",
    "        return outputs, h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, cnn_autoencoder, lstm_model, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f47c0",
   "metadata": {},
   "source": [
    "### Training ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "744f0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_autoencoder_model = CNNAutoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(cnn_autoencoder_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e3040d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(model, train_loader, criterion, optimizer, nepoch=10):\n",
    "    for epoch in range(nepoch):\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            inputs = data.permute(0, 2, 1).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}/{nepoch}, Loss: {total_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d463c1bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.004455086859064648\n",
      "Epoch 2/10, Loss: 0.0014397300681825514\n",
      "Epoch 3/10, Loss: 0.0012297008528798017\n",
      "Epoch 4/10, Loss: 0.0011057490556042027\n",
      "Epoch 5/10, Loss: 0.001025197899776555\n",
      "Epoch 6/10, Loss: 0.000980121058014603\n",
      "Epoch 7/10, Loss: 0.000935201107548644\n",
      "Epoch 8/10, Loss: 0.0008989490218632239\n",
      "Epoch 9/10, Loss: 0.0008759206383288526\n",
      "Epoch 10/10, Loss: 0.000859810766664472\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_cnn(cnn_autoencoder_model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d5e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "torch.save(cnn_autoencoder_model.state_dict(), \"./models/cnn_autoencoder.pth\")\n",
    "print(f\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1776046",
   "metadata": {},
   "source": [
    "### Plotting ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(waveform_df, segment_length=1000, start_index=0):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for col in waveform_df.columns:\n",
    "        plt.plot(waveform_df.index, waveform_df[col], label=f'Lead {col}')\n",
    "    \n",
    "    plt.title('ECG Waveform')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f90630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "392bbb1a",
   "metadata": {},
   "source": [
    "## TCN Autoencoder ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb809b3d",
   "metadata": {},
   "source": [
    "Model Card for the Hybrid Autoencoder Model Name: Hybrid Autoencoder for ECG and Metadata\n",
    "\n",
    "Description: This model is designed to learn compressed representations of combined ECG waveform and patient metadata. It utilizes separate pathways for waveform data and metadata, merging them into a dense representation which is then used to reconstruct both types of data.\n",
    "\n",
    "Model Architecture:\n",
    "\n",
    "Waveform Pathway: Convolutional layers followed by pooling and flattening. Metadata Pathway: Dense layers. Combined Encoding and Decoding: Dense layers. Intended Use: Intended for anomaly detection in ECG data where additional patient metadata is available and considered relevant.\n",
    "\n",
    "Data Used for Training: Assumes a dataset comprising ECG waveform data aligned with patient metadata such as age, sex, and device information.\n",
    "\n",
    "Limitations: The model's effectiveness is highly dependent on the quality and preprocessing of the input data. The architecture needs fine-tuning and validation using real-world data to ensure robustness.\n",
    "\n",
    "Ethical Considerations: Care should be taken to avoid biases that may arise from imbalanced data across different demographic groups. Privacy concerns should be addressed when handling patient data.\n",
    "\n",
    "This framework sets up the foundation of your model; further tuning, training, and validation steps are needed to adapt it to specific tasks or datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f9a2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique devices: 11\n"
     ]
    }
   ],
   "source": [
    "num_unique_devices = metadata['device'].nunique()\n",
    "print(f\"Number of unique devices: {num_unique_devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "843f9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tcn import TCN\n",
    "\n",
    "class TCNAutoencoder(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size, dropout, metadata_dims):\n",
    "        super(TCNAutoencoder, self).__init__()\n",
    "        self.encoder = TCN(\n",
    "            num_inputs=num_inputs,\n",
    "            num_channels=num_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            dropout=dropout,\n",
    "            causal=True,\n",
    "        )\n",
    "        self.age_embedding = nn.Linear(1, metadata_dims[0])  # Age is a single value\n",
    "        self.sex_embedding = nn.Linear(2, metadata_dims[1])  # Sex is one-hot encoded (2 columns)\n",
    "        self.device_embedding = nn.Linear(num_unique_devices, metadata_dims[2]) #one hot (11 cols)\n",
    "        self.validated_embedding = nn.Linear(2, metadata_dims[3]) #one hot (2 cols)\n",
    "        \n",
    "        decoder_input_dim = num_channels[-1] + sum(metadata_dims)\n",
    "        self.decoder = TCN(\n",
    "            num_inputs=decoder_input_dim,\n",
    "            num_channels=num_channels[::-1],\n",
    "            kernel_size=kernel_size,\n",
    "            dropout=dropout,    \n",
    "            causal=True,\n",
    "            output_projection=num_inputs,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, metadata):\n",
    "        encoded = self.encoder(x)\n",
    "        \n",
    "        age_emb = self.age_embedding(metadata[:, 0].unsqueeze(1))\n",
    "        sex_emb = self.sex_embedding(metadata[:, 1:3])\n",
    "        device_emb = self.device_embedding(metadata[:, 3:-2])\n",
    "        validated_emb = self.validated_embedding(metadata[:, -2:])\n",
    "        \n",
    "        metadata_emb = torch.cat([age_emb, sex_emb, device_emb, validated_emb], dim=-1)\n",
    "        metadata_emb = metadata_emb.unsqueeze(2).expand(-1, -1, encoded.size(2))\n",
    "        \n",
    "        concatenated = torch.cat([encoded, metadata_emb], dim=1)\n",
    "        decoded = self.decoder(concatenated)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e042cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19601, 16)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_inputs = 12  # Assuming 12 input channels in the ECG data\n",
    "num_channels = [32, 64, 128]  # Example number of channels in each residual block of the encoder\n",
    "kernel_size = 3  # Example kernel size for the TCN layers\n",
    "dropout = 0.2  # Example dropout rate\n",
    "metadata_dims = [10, 5, 20, 5]  # Example embedding dimensions for age, sex, and device\n",
    "\n",
    "num_unique_devices = metadata['device'].nunique()\n",
    "print(normalized_metadata_train.shape)\n",
    "assert num_unique_devices == normalized_metadata_train.shape[1] - 5, \"Number of unique devices should match the number of device columns in metadata\"\n",
    "\n",
    "model = TCNAutoencoder(num_inputs, num_channels, kernel_size, dropout, metadata_dims)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(normalized_waveform_train).float(), torch.from_numpy(normalized_metadata_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c798882b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0006\n",
      "Epoch [2/10], Loss: 0.0003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     reconstructed_data \u001b[38;5;241m=\u001b[39m model(ecg_data, batch_metadata)\n\u001b[0;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(reconstructed_data, ecg_data)\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeffz\\anaconda3\\envs\\neural_net\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_data, batch_metadata in train_loader:\n",
    "        ecg_data = batch_data.to(device).permute(0, 2, 1).float()\n",
    "        batch_metadata = batch_metadata.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        reconstructed_data = model(ecg_data, batch_metadata)\n",
    "        loss = criterion(reconstructed_data, ecg_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
